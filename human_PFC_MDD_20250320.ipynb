{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAPIDS & Scanpy Single-Cell RNA-seq Workflow on PFC cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2020, NVIDIA CORPORATION.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\") you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0 \n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates a single-cell RNA analysis workflow that begins with preprocessing a count matrix of size `(n_gene, n_cell)` and results in a visualization of the clustered cells for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes, we use a dataset of 1.3 M brain cells with Unified Virtual Memory to oversubscribe GPU memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "import scipy.io\n",
    "import scipy.sparse\n",
    "\n",
    "import time\n",
    "import os, wget\n",
    "\n",
    "\n",
    "import cudf\n",
    "\n",
    "from cuml.decomposition import PCA\n",
    "from cuml.manifold import TSNE\n",
    "from cuml.cluster import KMeans\n",
    "from cuml.preprocessing import StandardScaler\n",
    "\n",
    "import cuml\n",
    "import rapids_scanpy_funcs\n",
    "import utils\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', 'Expected ')\n",
    "warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "import rmm\n",
    "\n",
    "from rmm.allocators.cupy import rmm_cupy_allocator\n",
    "import cupy\n",
    "cupy.cuda.set_allocator(rmm_cupy_allocator)\n",
    "from scipy import sparse\n",
    "import gc\n",
    "import cupy as cp\n",
    "gc.collect()\n",
    "cp.get_default_memory_pool().free_all_blocks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the RAPIDS memory manager to enable Unified Virtual Memory management, which allows us to oversubscribe the GPU memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we provide the path to the sparse `.h5ad` file containing the count matrix to analyze. Please see the README for instructions on how to download the dataset we use here.\n",
    "\n",
    "To run this notebook using your own dataset, please see the README for instructions to convert your own count matrix into this format. Then, replace the path in the cell below with the path to your generated `.h5ad` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mtx_path=r\"/temp/data/human_MDD_PFC/GSE144136_GeneBarcodeMatrix_Annotated.mtx\"\n",
    "cell_name_path=r\"/temp/data/human_MDD_PFC/GSE144136_CellNames.csv\"\n",
    "gene_name_path=r\"/temp/data/human_MDD_PFC/GSE144136_GeneNames.csv\"\n",
    "\n",
    "genes = pd.read_csv(gene_name_path)\n",
    "cells = pd.read_csv(cell_name_path)\n",
    "adata=sc.read_mtx(mtx_path)\n",
    "adata=adata.T\n",
    "adata.obs_names = cells.x\n",
    "adata.var_names = genes.x\n",
    "adata.X=sparse.csr_matrix(adata.X)\n",
    "adata.write(\"/temp/data/human_MDD_PFC/merged_data.h5ad\")\n",
    "#arr = scipy.io.mmread(mtx_path).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adata.X)\n",
    "#print(adata.obs_names)\n",
    "print(genes.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype_df=pd.DataFrame(cells.x.str.split(\".\",expand=True))\n",
    "barcode_df=celltype_df.iloc[:,1].str.split(\"_\",expand=True)\n",
    "barcode_df2=pd.concat([celltype_df.iloc[:,0],barcode_df],axis=1)\n",
    "barcode_df2=barcode_df2.set_axis([\"celltype\",\"subject\",\"case_control\",\"batch\",\"barcode\"],axis=\"columns\")\n",
    "b_df3=barcode_df2.copy()\n",
    "b_df3.index=adata.obs.index\n",
    "obs_col=[\"celltype\",\"subject\",\"case_control\",\"batch\",\"barcode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess_in_bulk\n",
      "['CX3CR1', 'CLDN5', 'GLUL', 'NDRG2', 'PCDH15', 'PLP1', 'MBP', 'SATB2', 'SLC17A7', 'SLC17A6', 'GAD2', 'GAD1', 'SNAP25', 'HTR1A', 'HTR1B', 'HTR1D', 'HTR1E', 'HTR2A', 'HTR2B', 'HTR2C', 'HTR3A', 'HTR4', 'HTR5A', 'HTR6', 'HTR7', 'DRD1', 'DRD2', 'DRD3', 'DRD4', 'DRD5', 'HRH1', 'HRH2', 'HRH3', 'CHRM1', 'CHRM2', 'CHRM3', 'CHRM4', 'CHRM5', 'ADRA1A', 'ADRA1B', 'ADRA2A', 'ADRA2B', 'ADRA2C', 'ADRB1', 'ADRB2']\n",
      "perform regression\n",
      "perform scale\n",
      "float32\n",
      "Total Preprocessing time: 11.146785497665405\n",
      "shape of adata: (35184, 29432)\n",
      "shape of adata: (35184, 29432)\n",
      "perform PCA\n",
      "40\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuSOLVER error encountered at: file=/opt/conda/include/raft/linalg/detail/eig.cuh line=118: ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcalculation_tool\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mct\u001b[39;00m\n\u001b[32m      2\u001b[39m file_path=\u001b[33m\"\u001b[39m\u001b[33m/data/human_MDD_PFC/merged_control_data.h5ad\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m adata,GPCR_df=\u001b[43mct\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpreprocess_adata_in_bulk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m GPCR_df.to_csv(\u001b[33m\"\u001b[39m\u001b[33m/data/human_MDD_PFC/combined_data_GPCR_df.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/antipsychotics-scRNAseq2/calculation_tool.py:232\u001b[39m, in \u001b[36mpreprocess_adata_in_bulk\u001b[39m\u001b[34m(adata_path, label, add_markers)\u001b[39m\n\u001b[32m    230\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mperform PCA\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    231\u001b[39m \u001b[38;5;28mprint\u001b[39m(params[\u001b[33m\"\u001b[39m\u001b[33mn_pca_batches\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m adata = \u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpca\u001b[49m\u001b[43m(\u001b[49m\u001b[43madata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn_components\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m              \u001b[49m\u001b[43mtrain_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpca_train_ratio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m              \u001b[49m\u001b[43mn_batches\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn_pca_batches\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m              \u001b[49m\u001b[43mgpu\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[38;5;66;03m#t-sne + k-means\u001b[39;00m\n\u001b[32m    238\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mt-sne\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/antipsychotics-scRNAseq2/utils.py:32\u001b[39m, in \u001b[36mpca\u001b[39m\u001b[34m(adata, n_components, train_ratio, n_batches, gpu)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdecomposition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m pca = \u001b[43mPCA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43madata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m embeddings = np.zeros((adata.X.shape[\u001b[32m0\u001b[39m], n_components))\n\u001b[32m     35\u001b[39m batch_size = \u001b[38;5;28mint\u001b[39m(embeddings.shape[\u001b[32m0\u001b[39m] / n_batches)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/cuml/internals/api_decorators.py:193\u001b[39m, in \u001b[36m_make_decorator_function.<locals>.decorator_function.<locals>.decorator_closure.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    190\u001b[39m     set_api_output_dtype(output_dtype)\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m process_return:\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/cuml/internals/api_decorators.py:416\u001b[39m, in \u001b[36menable_device_interop.<locals>.dispatch\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdispatch_func\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    415\u001b[39m     func_name = gpu_func.\u001b[34m__name__\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdispatch_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    418\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m gpu_func(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/cuml/internals/api_decorators.py:195\u001b[39m, in \u001b[36m_make_decorator_function.<locals>.decorator_function.<locals>.decorator_closure.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    193\u001b[39m         ret = func(*args, **kwargs)\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cm.process_return(ret)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mbase.pyx:764\u001b[39m, in \u001b[36mcuml.internals.base.UniversalBase.dispatch_func\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpca.pyx:487\u001b[39m, in \u001b[36mcuml.decomposition.pca.PCA.fit\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mRuntimeError\u001b[39m: cuSOLVER error encountered at: file=/opt/conda/include/raft/linalg/detail/eig.cuh line=118: "
     ]
    }
   ],
   "source": [
    "import calculation_tool as ct\n",
    "file_path=\"/data/human_MDD_PFC/merged_control_data.h5ad\"\n",
    "adata,GPCR_df=ct.preprocess_adata_in_bulk(file_path,label=None)\n",
    "GPCR_df.to_csv(\"/data/human_MDD_PFC/combined_data_GPCR_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=\"/data/human_MDD_PFC/merged_control_data.h5ad\"\n",
    "adata=anndata.read_h5ad(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_R_mtx,GPCR_type_df,drug_list,GPCR_list=ct.load_parameters()\n",
    "params=ct.set_parameters_for_preprocess(GPCR_list)\n",
    "import calculation_tool as ct\n",
    "ct.drug_titeration(adata, GPCR_df, GPCR_type_df, drug_list, D_R_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_genes_dict = {\n",
    "    \"Neuron\": [\"RBFOX3\", \"MAP2\", \"SLC17A7\", \"SATB2\", \"CUX2\",\"BCL11B\", \"FEZF2\",\"TLE4\", \"FOXP2\",\"GAD1\",\"PVALB\",\"SST\",\"VIP\"],\n",
    "    \"Astrocyte\": [\"GFAP\", \"AQP4\", \"ALDH1L1\"],\n",
    "    \"Oligodendrocyte\": [\"MBP\", \"MOG\", \"OLIG1\", \"OLIG2\"],\n",
    "    \"Microglia\": [\"TMEM119\", \"AIF1\", \"CD68\", \"CX3CR1\"],\n",
    "    \"Endothelial\": [\"CLDN5\", \"PECAM1\", \"VWF\"],\n",
    "    \"OPC\": [\"PDGFRA\", \"CSPG4\"],\n",
    "    \"Ependymal\": [\"FOXJ1\"]\n",
    "}\n",
    "sc.pl.dotplot(adata, marker_genes_dict, \"leiden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPCR_adata=anndata.AnnData(X=GPCR_df)\n",
    "GPCR_adata_norm=sc.pp.normalize_total(GPCR_adata,target_sum=1e4,inplace=False)['X']\n",
    "GPCR_adata_norm_df=pd.DataFrame(GPCR_adata_norm,columns=GPCR_adata.var.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_inhibit_pattern(adata,GPCR_adata_norm_df,GPCR_type_df,drug_conc,n_pattern=10000):\n",
    "    # 前提：以下の変数は既に定義されているものとする\n",
    "    # adata: シングルセル解析の AnnData オブジェクト（obs に \"is_clz_selective\" などが含まれる）\n",
    "    # GPCR_adata_norm_df: 正規化済み GPCR 発現データの DataFrame（行=細胞, 列=受容体名）\n",
    "    # GPCR_type_df: 受容体タイプの DataFrame（列: receptor_name, type）; type は \"Gs\", \"Gi\" 等\n",
    "    # drug_conc: 薬剤濃度（scalar）\n",
    "    # ※ D_R_mtx は本コードでは使用せず、effective Ki 値によりシミュレーションする\n",
    "    from tqdm import tqdm  # 追加：進捗バー用ライブラリ\n",
    "    # 1. adata.obs の \"is_clz_selective\" に基づき、グループ分けするためのマスクを作成\n",
    "    mask = adata.obs['is_clz_selective'].astype(bool) == True\n",
    "    mask.index = pd.RangeIndex(start=0, stop=adata.obs['is_clz_selective'].shape[0], step=1)\n",
    "    # 2. GPCRのリストおよび GPCR_type_df のフィルタリング\n",
    "    # \"Unnamed: 0\" を除外したカラムリストを作成\n",
    "    GPCR_list2 = [col for col in GPCR_adata_norm_df.columns if col != \"Unnamed: 0\"]\n",
    "    # 全細胞の GPCR 発現データ（正規化済み）の DataFrame を用意\n",
    "    # ※ GPCR_adata_norm_df の index と adata.obs_names が整合している前提\n",
    "    all_expr = pd.DataFrame(GPCR_adata_norm_df, index=GPCR_adata_norm_df.index, columns=GPCR_list2)\n",
    "\n",
    "    #GPCR_type_df = GPCR_type_df[GPCR_type_df.receptor_name.isin(GPCR_list2)]\n",
    "    Gs = GPCR_type_df[GPCR_type_df.type == \"Gs\"][\"receptor_name\"].values\n",
    "    Gi = GPCR_type_df[GPCR_type_df.type == \"Gi\"][\"receptor_name\"].values\n",
    "    # expression_df に存在し、かつ effective_Ki にも存在する GPCR のみを抽出\n",
    "    Gs_filtered = [gene for gene in Gs if (gene + '_raw' in all_expr.columns)]\n",
    "    Gi_filtered = [gene for gene in Gi if (gene + '_raw' in all_expr.columns)]\n",
    "\n",
    "    # フィルタ後のリストから、expression_df の列名用リストを作成\n",
    "    Gs_cols = [gene + '_raw' for gene in Gs_filtered]\n",
    "    Gi_cols = [gene + '_raw' for gene in Gi_filtered]\n",
    "\n",
    "    # 4. ランダムな受容体阻害パターンを 10,000 パターン生成\n",
    "    unique_patterns_set = set()\n",
    "    pattern_dict = {}\n",
    "    i = 0\n",
    "    #n_pattern=10\n",
    "    while len(unique_patterns_set) < n_pattern:\n",
    "        random_pattern = np.random.randint(2, size=len(GPCR_list2))\n",
    "        pattern_str = ''.join(map(str, random_pattern))\n",
    "        if pattern_str not in unique_patterns_set:\n",
    "            unique_patterns_set.add(pattern_str)\n",
    "            # 各パターンは、受容体ごとに True (阻害する) / False (阻害しない) の辞書とする\n",
    "            pattern_dict[f\"Pattern_{i+1}\"] = {gpcr: bool(val) for gpcr, val in zip(GPCR_list2, random_pattern)}\n",
    "            i += 1\n",
    "\n",
    "    # オプション：最初の5パターンを確認\n",
    "    for key in list(pattern_dict.keys())[:5]:\n",
    "        print(f\"{key}: {pattern_dict[key]}\")\n",
    "\n",
    "    def simulate_response_all(expression_df, pattern, drug_conc, Gs_cols, Gi_cols):\n",
    "        \"\"\"\n",
    "        expression_df: 各細胞の受容体発現 (DataFrame, 行=細胞, 列=受容体)\n",
    "        pattern: 受容体阻害パターン（辞書, receptor -> bool, True=阻害する）\n",
    "        drug_list: 薬剤名のリスト\n",
    "        drug_conc: 薬剤濃度（scalar）\n",
    "        Gs, Gi: Gs, Gi タイプ受容体名の配列\n",
    "        \"\"\"\n",
    "        # 阻害パターンに応じた effective Ki の設定\n",
    "        # 阻害する受容体は Ki = 0.01、阻害しない受容体は Ki = 10000\n",
    "        #effective_Ki = pd.Series({receptor: (0.01 if pattern[receptor] else 10000)\n",
    "        #                          for receptor in expression_df.columns})\n",
    "        effective_Ki = pd.Series({\n",
    "        receptor: (0.01 if pattern[receptor] else 10000)\n",
    "        for receptor in expression_df.columns\n",
    "        })\n",
    "        #print(effective_Ki)\n",
    "        responses = {}\n",
    "        # Gs 効果・Gi 効果を計算\n",
    "        gs_effect = (expression_df[Gs_cols].divide(1 + drug_conc / effective_Ki[Gs_cols])).sum(axis=1)\n",
    "        gi_effect = (expression_df[Gi_cols].divide(1 + drug_conc / effective_Ki[Gi_cols])).sum(axis=1)\n",
    "        basal_cAMP = (expression_df[Gs_cols] - expression_df[Gi_cols]).sum(axis=1)\n",
    "        cAMPmod = (gs_effect - gi_effect) - basal_cAMP\n",
    "        #print(\"cAMPmod\")\n",
    "        #print(cAMPmod.sum())\n",
    "        \n",
    "        # 細胞ごとの cAMPmod の Series とする\n",
    "        responses= cAMPmod\n",
    "        return responses\n",
    "\n",
    "    # 6. 各阻害パターンについて、全細胞でシミュレーションした後、clz_selective と非選択細胞間の差分を算出\n",
    "    results = []\n",
    "    # tqdm を用いて進捗状況を表示\n",
    "    for pattern_name, pattern in tqdm(pattern_dict.items(), total=len(pattern_dict), desc=\"Simulating drug responses\"):\n",
    "        # 全細胞でのシミュレーション結果を得る\n",
    "        all_responses = simulate_response_all(all_expr, pattern, drug_conc, Gs_cols, Gi_cols)\n",
    "        #print(all_responses)\n",
    "        # 各薬剤について、mask_aligned を用いて clz_selective と非選択細胞群の平均値を計算\n",
    "        selective_mean = all_responses[mask].mean()\n",
    "        nonselective_mean = all_responses[~mask].mean()\n",
    "        diff= selective_mean - nonselective_mean\n",
    "        #print(diff)\n",
    "        results.append({\n",
    "            'pattern_name':pattern_name,\n",
    "            'pattern': pattern,\n",
    "            'diff': diff\n",
    "        })\n",
    "\n",
    "    # 7. 結果を DataFrame に変換し、diff の大きい順にソート\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df_sorted = results_df.sort_values(by='diff', ascending=False)\n",
    "\n",
    "    # 上位のパターンを確認（例：上位5件）\n",
    "    print(results_df_sorted.head())\n",
    "\n",
    "    return results_df_sorted,all_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import calculation_tool as ct\n",
    "\n",
    "drug_conc=10**4\n",
    "results_df_sorted,all_responses=sim_inhibit_pattern(adata,GPCR_adata_norm_df,GPCR_type_df,drug_conc,n_pattern=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=\"/data/human_MDD_PFC\"\n",
    "results_df_sorted.to_csv(os.path.join(dir,\"results_df_sorted.csv\"))\n",
    "all_responses.to_csv(os.path.join(dir,\"all_responses.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.visualize_patterns(results_df_sorted, top_n=20, top_n_for_heatmap=20, scatter_n=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
