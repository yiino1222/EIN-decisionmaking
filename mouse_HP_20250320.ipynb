{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAPIDS & Scanpy Single-Cell RNA-seq Workflow on mouse NAc cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2020, NVIDIA CORPORATION.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\") you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0 \n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates a single-cell RNA analysis workflow that begins with preprocessing a count matrix of size `(n_gene, n_cell)` and results in a visualization of the clustered cells for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes, we use a dataset of 1.3 M brain cells with Unified Virtual Memory to oversubscribe GPU memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "\n",
    "import time\n",
    "import os, wget\n",
    "\n",
    "import cupy as cp\n",
    "import cudf\n",
    "\n",
    "from cuml.decomposition import PCA\n",
    "from cuml.manifold import TSNE\n",
    "from cuml.cluster import KMeans\n",
    "from cuml.preprocessing import StandardScaler\n",
    "\n",
    "import rapids_scanpy_funcs\n",
    "import utils\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', 'Expected ')\n",
    "warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "from sh import gunzip\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "import rmm\n",
    "rmm.reinitialize(managed_memory=True)\n",
    "from rmm.allocators.cupy import rmm_cupy_allocator\n",
    "import cupy\n",
    "cupy.cuda.set_allocator(rmm_cupy_allocator)\n",
    "\n",
    "import calculation_tool as ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the RAPIDS memory manager to enable Unified Virtual Memory management, which allows us to oversubscribe the GPU memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we provide the path to the sparse `.h5ad` file containing the count matrix to analyze. Please see the README for instructions on how to download the dataset we use here.\n",
    "\n",
    "To run this notebook using your own dataset, please see the README for instructions to convert your own count matrix into this format. Then, replace the path in the cell below with the path to your generated `.h5ad` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "url_list=[r\"https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSM5482106&format=file&file=GSM5482106%5FNAc%5FWT%5FRep1%5Fbarcodes%2Etsv%2Egz\",\n",
    "r\"https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSM5482106&format=file&file=GSM5482106%5FNAc%5FWT%5FRep1%5Ffeatures%2Etsv%2Egz\",\n",
    "r\"https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSM5482106&format=file&file=GSM5482106%5FNAc%5FWT%5FRep1%5Fmatrix%2Emtx%2Egz\",\n",
    "r\"https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSM5482107&format=file&file=GSM5482107%5FNAc%5FWT%5FRep2%5Fbarcodes%2Etsv%2Egz\",\n",
    "r\"https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSM5482107&format=file&file=GSM5482107%5FNAc%5FWT%5FRep2%5Ffeatures%2Etsv%2Egz\",\n",
    "r\"https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSM5482107&format=file&file=GSM5482107%5FNAc%5FWT%5FRep2%5Fmatrix%2Emtx%2Egz\",\n",
    "r\"https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSM5482108&format=file&file=GSM5482108%5FNAc%5FSetd1aHet%5FRep1%5Fbarcodes%2Etsv%2Egz\",\n",
    "r\"https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSM5482108&format=file&file=GSM5482108%5FNAc%5FSetd1aHet%5FRep1%5Ffeatures%2Etsv%2Egz\",\n",
    "r\"https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSM5482108&format=file&file=GSM5482108%5FNAc%5FSetd1aHet%5FRep1%5Fmatrix%2Emtx%2Egz\",\n",
    "r\"https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSM5482109&format=file&file=GSM5482109%5FNAc%5FSetd1aHet%5FRep2%5Fbarcodes%2Etsv%2Egz\",\n",
    "r\"https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSM5482109&format=file&file=GSM5482109%5FNAc%5FSetd1aHet%5FRep2%5Ffeatures%2Etsv%2Egz\",\n",
    "r\"https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSM5482109&format=file&file=GSM5482109%5FNAc%5FSetd1aHet%5FRep2%5Fmatrix%2Emtx%2Egz\"]\n",
    "\n",
    "def download_file(url, dir, file_name):\n",
    "    full_path = os.path.join(dir, file_name)\n",
    "    urllib.request.urlretrieve(url, full_path)\n",
    "    # 以下のコメントアウト部分を活用する場合は、解凍の手順を追加することができます。\n",
    "    # with gzip.open(full_path, 'rb') as f_in:\n",
    "    #     with open(full_path[:-3], 'wb') as f_out:\n",
    "    #         shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "dir = \"/data/mouse_NAc/\"\n",
    "\n",
    "for url in url_list:\n",
    "    acc = url.split(\"acc=\")[1].split(\"&\")[0]\n",
    "    file_name_from_url = url.split(\"file=\")[1]\n",
    "\n",
    "    # WTとSetd1aHetのサブフォルダを作成\n",
    "    subfolder = \"WT\" if \"WT\" in file_name_from_url else \"Setd1aHet\"\n",
    "    acc_dir = os.path.join(dir,subfolder, acc)\n",
    "    os.makedirs(acc_dir, exist_ok=True)\n",
    "\n",
    "    # 標準的なファイル名に変更（.gzを取り除く）\n",
    "    standard_file_name = file_name_from_url.split('_')[-1].replace('.gz', '')\n",
    "    \n",
    "    if \"barcodes\" in file_name_from_url:\n",
    "        standard_file_name = \"barcodes.tsv.gz\"\n",
    "    elif \"features\" in file_name_from_url:\n",
    "        standard_file_name = \"features.tsv.gz\"\n",
    "    elif \"matrix\" in file_name_from_url:\n",
    "        standard_file_name = \"matrix.mtx.gz\"\n",
    "    \n",
    "    # ファイルをダウンロード\n",
    "    download_file(url, acc_dir, standard_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ダウンロードディレクトリ\n",
    "base_dir = \"/data/mouse_NAc/\"\n",
    "\n",
    "def read_10x_mtx(path, label):\n",
    "    \"\"\"10x mtxフォーマットのデータを読み込み、指定されたラベルを追加します。\"\"\"\n",
    "    adata = sc.read_10x_mtx(\n",
    "        path,\n",
    "        var_names='gene_symbols',\n",
    "        cache=True\n",
    "    )\n",
    "    adata.obs['label'] = label\n",
    "    return adata\n",
    "\n",
    "labels = [\"WT\", \"Setd1aHet\"]\n",
    "\n",
    "all_adatas = []\n",
    "\n",
    "for label in labels:\n",
    "    label_dir = os.path.join(base_dir, label)\n",
    "    gsm_dirs = [os.path.join(label_dir, d) for d in os.listdir(label_dir) if os.path.isdir(os.path.join(label_dir, d))]\n",
    "    \n",
    "    for gsm_dir in gsm_dirs:\n",
    "        if os.path.exists(gsm_dir):\n",
    "            all_adatas.append(read_10x_mtx(gsm_dir, label))\n",
    "\n",
    "# 全てのAnnDataオブジェクトを1つに結合\n",
    "combined_adata = all_adatas[0].concatenate(all_adatas[1:], join='outer')\n",
    "\n",
    "# .h5ad形式で保存\n",
    "combined_adata.write(\"/data/mouse_NAc/combined_data.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=\"/data/mouse_hippocampus/GSE60361_C1-3005-Expression.txt\"\n",
    "df=pd.read_csv(file_path, delimiter=\"\\t\",header=0,index_col=0)\n",
    "adata = anndata.read_csv(file_path, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1772071015_C02', '1772071017_G12', '1772071017_A05', '1772071014_B06',\n",
       "       '1772067065_H06', '1772071017_E02', '1772067065_B07', '1772067060_B09',\n",
       "       '1772071014_E04', '1772071015_D04',\n",
       "       ...\n",
       "       '1772066110_D12', '1772071017_A07', '1772063071_G10', '1772058148_C03',\n",
       "       '1772063061_D09', '1772067059_B04', '1772066097_D04', '1772063068_D01',\n",
       "       '1772066098_A12', '1772058148_F03'],\n",
       "      dtype='object', length=3005)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Tspan12', 'Tshz1', 'Fnbp1l', 'Adamts15', 'Cldn12', 'Rxfp1',\n",
       "       '2310042E22Rik', 'Sema3c', 'Jam2', 'Apbb1ip',\n",
       "       ...\n",
       "       'Gm20826_loc1', 'Gm20826_loc2', 'Gm20877_loc2', 'Gm20877_loc1',\n",
       "       'Gm20865_loc4', 'Gm20738_loc4', 'Gm20738_loc6', 'Gm21943_loc1',\n",
       "       'Gm21943_loc3', 'Gm20738_loc3'],\n",
       "      dtype='object', name='cell_id', length=19972)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess_in_bulk\n",
      "HTR1E is not included\n",
      "HTR1E is removed from marker list\n",
      "['CX3CR1', 'CLDN5', 'GLUL', 'NDRG2', 'PCDH15', 'PLP1', 'MBP', 'SATB2', 'SLC17A7', 'SLC17A6', 'GAD2', 'GAD1', 'SNAP25', 'HTR1A', 'HTR1B', 'HTR1D', 'HTR2A', 'HTR2B', 'HTR2C', 'HTR3A', 'HTR4', 'HTR5A', 'HTR6', 'HTR7', 'DRD1', 'DRD2', 'DRD3', 'DRD4', 'DRD5', 'HRH1', 'HRH2', 'HRH3', 'CHRM1', 'CHRM2', 'CHRM3', 'CHRM4', 'CHRM5', 'ADRA1A', 'ADRA1B', 'ADRA2A', 'ADRA2B', 'ADRA2C', 'ADRB1', 'ADRB2']\n",
      "perform regression\n",
      "perform scale\n",
      "float32\n",
      "Total Preprocessing time: 19.9202721118927\n",
      "shape of adata: (38956, 21594)\n",
      "shape of adata: (38956, 21594)\n",
      "perform PCA\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import calculation_tool as ct\n",
    "file_path=\"/data/mouse_NAc/combined_data.h5ad\"\n",
    "adata=ct.preprocess_adata_in_bulk(file_path,label=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_R_mtx,GPCR_type_df,drug_list,GPCR_list=ct.load_parameters()\n",
    "params=ct.set_parameters_for_preprocess(GPCR_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=[\"leiden\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "import math\n",
    "\n",
    "# 1. ラベル毎に処理するための準備\n",
    "unique_labels = adata.obs['label'].unique()\n",
    "\n",
    "# 2. 各ラベルについて、各クラスタの薬剤反応の相関行列を計算\n",
    "drug_response_columns = ['cAMP_%s' % drug for drug in drug_list]\n",
    "\n",
    "# ラベル毎の相関行列を保存するための辞書\n",
    "correlation_matrices_per_label = {}\n",
    "\n",
    "for label in unique_labels:\n",
    "    adata_subset = adata[adata.obs[\"label\"] == label]  # ラベルに基づいてadataのサブセットを取得\n",
    "    \n",
    "    # サブセット内のクラスタを取得\n",
    "    clusters = adata_subset.obs['leiden'].cat.categories\n",
    "    correlation_matrices = {}\n",
    "    \n",
    "    for cluster in clusters:\n",
    "        subset = adata_subset.obs.loc[adata_subset.obs['leiden'] == cluster, drug_response_columns]\n",
    "        correlation_matrices[cluster] = subset.corr()\n",
    "    \n",
    "    correlation_matrices_per_label[label] = correlation_matrices\n",
    "\n",
    "# 3. 各ラベルの相関行列を1つのFigureにまとめてプロット\n",
    "for label, correlation_matrices in correlation_matrices_per_label.items():\n",
    "    num_clusters = len(correlation_matrices)\n",
    "    \n",
    "    # 4つのクラスタごとに新しい行を作成する\n",
    "    rows = math.ceil(num_clusters / 4)\n",
    "    fig = plt.figure(figsize=(40, rows * 10))  # 1つの相関行列あたりの横幅を10として計算\n",
    "    spec = gridspec.GridSpec(rows, 4, figure=fig)  # 4列のグリッドを作成\n",
    "    \n",
    "    for i, (cluster, corr_matrix) in enumerate(correlation_matrices.items()):\n",
    "        ax = fig.add_subplot(spec[i // 4, i % 4])\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, ax=ax)\n",
    "        ax.set_title(f'Cluster {cluster}')\n",
    "    \n",
    "    fig.suptitle(f'Correlation Matrices for Label {label}', fontsize=20, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adataからobs_namesを取得\n",
    "var_names = adata.var_names.tolist()\n",
    "\n",
    "# obs_namesに含まれる要素だけをgene_of_interestから残す\n",
    "filtered_genes = [gene for gene in params['markers'] if gene in var_names]\n",
    "print(filtered_genes)\n",
    "sc.pl.dotplot(adata, var_names=filtered_genes, groupby='leiden')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
